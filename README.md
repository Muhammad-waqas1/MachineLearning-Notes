![GitHub Repo stars](https://img.shields.io/github/stars/Muhammad-waqas1/MachineLearning-Notes)
![GitHub forks](https://img.shields.io/github/forks/Muhammad-waqas1/MachineLearning-Notes)
![MIT License](https://img.shields.io/github/license/Muhammad-waqas1/MachineLearning-Notes)

# Machine Learning Study Notes

This repository contains structured **Jupyter Notebook notes** based on Machine Learning. Each notebook is dedicated to a single Lecture, capturing the intuition, math, and key takeaways in a concise and revision-friendly format.

## 🗂️ Table of Contents

| #   | Notebook Title                                                                 |
|-----|---------------------------------------------------------------------------------|
| 1   | [Introduction To Machine Learning Algorithms](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks) |
| 2   | [Simple Linear Regression Algorithm Indepth Maths Intuition With Notes](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/2. Simple Linear Regression Algorithm Indepth Maths Intuition With Notes.ipynb) |
| 3   | [Linear Regression Practical Implementation](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/3. Linear Regression Practical Implementation.ipynb) |
| 4   | [Mean Sqaured Error, Mean Absolute Error And RMSE- Linear Regression](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/4. Mean Sqaured Error, Mean Absolute Error And RMSE- Linear Regression.ipynb) |
| 5   | [Ridge And Lasso Regression Indepth Maths Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/5. Ridge And Lasso Regression Indepth Maths Intuition.ipynb) |
| 6   | [Ridge And Lasso Practical Implementation](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/6. Ridge And Lasso Practical Implementation.ipynb) |
| 7   | [ElasticNet Regression Machine Learning Algorithm Explained](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/7. ElasticNet Regression Machine Learning Algorithm Explained.ipynb) |
| 8   | [Logistic Regression Indepth Maths Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/8. Logistic Regression Indepth Maths Intuition.ipynb) |
| 9   | [Logistic Regression Practical Implementation In Python](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/9. Logistic Regression Practical Implementation In Python.ipynb) |
| 10  | [Naive Baye's Machine Learning Algorithm Indepth Inution- Part 1](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/10. Naive Baye's Machine Learning Algorithm Indepth Inution- Part 1.ipynb) |
| 11  | [Naive Baye's Machine Learning Algorithm Indepth Inution- Part 2](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/11. Naive Baye's Machine Learning Algorithm Indepth Inution- Part 2.ipynb) |
| 12  | [K Nearest Neighbour Indepth Intuition- Classification And Regression](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/12. K Nearest Neighbour Indepth Intuition- Classification And Regression.ipynb) |
| 13  | [Overfitting, Underfitting,Bias And Variance Explained](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/13. Overfitting, Underfitting,Bias And Variance Explained.ipynb) |
| 14  | [Performance Metrics, Accuracy,Precision,Recall And F-Beta Score Explained](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/14. Performance Metrics, Accuracy,Precision,Recall And F-Beta Score Explained.ipynb) |
| 15  | [Support Vector Machine Classifier Indepth Intution](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/15. Support Vector Machine Classifier Indepth Intution.ipynb) |
| 16  | [Support Vector Regression Indepth Maths Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/16. Support Vector Regression Indepth Maths Intuition.ipynb) |
| 17  | [How SVM Kernels Work?](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/17. How SVM Kernels Work?.ipynb) |
| 18  | [Part 1- Decision Tree Classifier Indepth Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/18. Part 1- Decision Tree Classifier Indepth Intuition.ipynb) |
| 19  | [Part 2- Post Prunning And Pre Prunning In Decision Tree Classifier](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/19. Part 2- Post Prunning And Pre Prunning In Decision Tree Classifier.ipynb) |
| 20  | [Part 3- Decision Tree And Post Prunning Practical Implementation](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/20. Part 3- Decision Tree And Post Prunning Practical Implementation.ipynb) |
| 21  | [Part 4- Decision Tree And Pre Prunning Practical Implementation](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/21. Part 4- Decision Tree And Pre Prunning Practical Implementation.ipynb) |
| 22  | [Part 5- Decision Tree Regression Indepth Intuition With Variance Reduction](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/22. Part 5- Decision Tree Regression Indepth Intuition With Variance Reduction.ipynb) |
| 23  | [Training Data Vs Test Data Vs Validation Data](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/23. Training Data Vs Test Data Vs Validation Data.ipynb) |
| 24  | [Cross Validation Using Python In Machine Learning](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/24. Cross Validation Using Python In Machine Learning.ipynb) |
| 25  | [Types Of Cross Validation In Machine Learning](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/25. Types Of Cross Validation In Machine Learning.ipynb) |
| 26  | [Ensemble Techniques-Bagging Vs Boosting](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/26. Ensemble Techniques-Bagging Vs Boosting.ipynb) |
| 27  | [Random Forest Regression And Classification Indepth Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/27. Random Forest Regression And Classification Indepth Intuition.ipynb) |
| 28  | [Out Of Bag(OOB) Evaluation And Error In Random Forest Indepth Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/28. Out Of Bag(OOB) Evaluation And Error In Random Forest Indepth Intuition.ipynb) |
| 29  | [Automated EDA Using Pandas Profiling](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/29. Automated EDA Using Pandas Profiling.ipynb) |
| 30  | [Automated EDA Using Autoviz Library With 3 Lines Of Code](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/30. Automated EDA Using Autoviz Library With 3 Lines Of Code.ipynb) |
| 31  | [In-depth EDA Using SweetViz Library In 2 Lines Of Code](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/31. In-depth EDA Using SweetViz Library In 2 Lines Of Code.ipynb) |
| 32  | [Complete Automated EDA Using Dtale Library Using 3 Lines Of Code](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/32. Complete Automated EDA Using Dtale Library Using 3 Lines Of Code.ipynb) |
| 33  | [R sqaured And Adjusted R squared Machine Learning](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/33. R sqaured And Adjusted R squared Machine Learning.ipynb) |
| 34  | [What Is Boosting Technique In Machine Learning](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/34. What Is Boosting Technique In Machine Learning.ipynb) |
| 35  | [Adaboost ML Algorithm Indepth Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/35. Adaboost ML Algorithm Indepth Intuition.ipynb) |
| 36  | [Gradient Boosting Algorithms Indepth Intuition](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/36. Gradient Boosting Algorithms Indepth Intuition.ipynb) |
| 37  | [Complete Unsupervised Machine Learning Tutorials- K Means,DBSCAN, Hierarchical Clustering](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/37. Complete Unsupervised Machine Learning Tutorials- K Means,DBSCAN, Hierarchical Clustering.ipynb) |
| 38  | [Complete Anomaly Detection Machine Learning Algorithms- Isolation Forest,DBSCAN,Local Factor Outlier](https://github.com/Muhammad-waqas1/MachineLearning-Notes/ML_Notebooks/38. Complete Anomaly Detection Machine Learning Algorithms- Isolation Forest,DBSCAN,Local Factor Outlier.ipynb) |



## What's Included

- 38 individual Jupyter Notebooks
- Notes written while watching each video
- Covers both theoretical intuition and practical aspects
- Ideal for revision, interviews, or quick concept refresh

## Purpose

- Reinforce concepts while learning
- Create a reference-friendly resource for others
- Openly document and share the learning journey

## How to Use

- Clone the repo:
  ```bash
  git clone https://github.com/Muhammad-waqas1/MachineLearning-Notes.git

- Open any .ipynb file in Jupyter or VS Code

- Read or add your own annotations as needed


> Made with curiosity, respect, and the intent to contribute back to the learning community.
